{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Paso a paso para realizar una automatización de los hiperparametros de un modelo de ML\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mi base de datos con las variables seleccionadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape:  (54231, 36)\n",
      "Test shape:  (6000, 36)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "\n",
    "datos = pd.read_csv('Datos/datos_c_seleccion.csv', index_col=0)\n",
    "# Separo labels de features\n",
    "labels=datos.target\n",
    "features = datos.drop(columns=['target'])\n",
    "# Divido Train y Test\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size = 6000, random_state = 42)\n",
    "print('Train shape: ', X_train.shape)\n",
    "print('Test shape: ', X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#armo el dataset para lgb\n",
    "train_set = lgb.Dataset(X_train, label = y_train)\n",
    "test_set = lgb.Dataset(X_test, label = y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimización Bayesiana"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Debemos especificar una función para optimizar, y sus correspondientes parametros, con sus valores límites."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generalmente la optimización es respecto a minimizar un valor, y como nuestra metrica es AUC ROC, donde cuanto más alto es mejor, la función objetico retoranará 1-AUC ROC CV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1- Nuestra función objetivo es optimizar los valores de los hyperarametros de LGBM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from hyperopt import STATUS_OK\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "def objective(hiperparemetros):\n",
    "    \"\"\"Objective function for Gradient Boosting Machine Hyperparameter Optimization.\n",
    "       Writes a new line to `outfile` on every iteration\"\"\"\n",
    "    \n",
    "    # Keep track of evals\n",
    "    global ITERATION\n",
    "    \n",
    "    ITERATION += 1\n",
    "    \n",
    "    # Using early stopping to find number of trees trained\n",
    "    if 'n_estimators' in hiperparemetros:\n",
    "        del hiperparemetros['n_estimators']\n",
    "    \n",
    "    # Retrieve the subsample\n",
    "    subsample = hiperparemetros['boosting_type'].get('subsample', 1.0)\n",
    "    \n",
    "    # Extract the boosting type and subsample to top level keys\n",
    "    hiperparemetros['boosting_type'] = hiperparemetros['boosting_type']['boosting_type']\n",
    "    hiperparemetros['subsample'] = subsample\n",
    "    \n",
    "    # Make sure parameters that need to be integers are integers\n",
    "    for parameter_name in ['num_leaves', 'subsample_for_bin', 'min_child_samples']:\n",
    "        hiperparemetros[parameter_name] = int(hiperparemetros[parameter_name])\n",
    "\n",
    "    start = timer()\n",
    "    \n",
    "    # Perform n_folds cross validation\n",
    "    cv_results = lgb.cv(hiperparemetros, train_set, num_boost_round = 10000, nfold = N_FOLDS, \n",
    "                        early_stopping_rounds = 100, metrics = 'auc', seed = 50)\n",
    "\n",
    "    run_time = timer() - start\n",
    "    \n",
    "    # Extract the best score\n",
    "    best_score = cv_results['auc-mean'][-1]\n",
    "    \n",
    "    # Loss must be minimized\n",
    "    loss = 1 - best_score\n",
    "    \n",
    "    # Boosting rounds that returned the highest cv score\n",
    "    n_estimators = len(cv_results['auc-mean'])\n",
    "    \n",
    "    # Add the number of estimators to the hiperparemetros\n",
    "    hiperparemetros['n_estimators'] = n_estimators\n",
    "\n",
    "    # Write to the csv file ('a' means append)\n",
    "    of_connection = open(OUT_FILE, 'a')\n",
    "    writer = csv.writer(of_connection)\n",
    "    writer.writerow([loss, hiperparemetros, ITERATION, run_time, best_score])\n",
    "    of_connection.close()\n",
    "\n",
    "    # Dictionary with information for evaluation\n",
    "    return {'loss': loss, 'hiperparemetros': hiperparemetros, 'iteration': ITERATION,\n",
    "            'train_time': run_time, 'status': STATUS_OK}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2- Parametros que debemos calibrar\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'boosting_type': 'gbdt',\n",
       " 'class_weight': None,\n",
       " 'colsample_bytree': 1.0,\n",
       " 'importance_type': 'split',\n",
       " 'learning_rate': 0.1,\n",
       " 'max_depth': -1,\n",
       " 'min_child_samples': 20,\n",
       " 'min_child_weight': 0.001,\n",
       " 'min_split_gain': 0.0,\n",
       " 'n_estimators': 100,\n",
       " 'n_jobs': -1,\n",
       " 'num_leaves': 31,\n",
       " 'objective': None,\n",
       " 'random_state': 50,\n",
       " 'reg_alpha': 0.0,\n",
       " 'reg_lambda': 0.0,\n",
       " 'silent': True,\n",
       " 'subsample': 1.0,\n",
       " 'subsample_for_bin': 200000,\n",
       " 'subsample_freq': 0}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = lgb.LGBMClassifier(random_state=50)\n",
    "hiperparemetros = model.get_params()\n",
    "hiperparemetros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3- Valores posibles de los parámetros para evaluar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the search space\n",
    "from hyperopt import hp\n",
    "\n",
    "space = {\n",
    "    'boosting_type': hp.choice('boosting_type', \n",
    "                                            [{'boosting_type': 'gbdt', 'subsample': hp.uniform('gdbt_subsample', 0.5, 1)}, \n",
    "                                             #{'boosting_type': 'dart', 'subsample': hp.uniform('dart_subsample', 0.5, 1)},\n",
    "                                             {'boosting_type': 'goss', 'subsample': 1.0}]),\n",
    "    'num_leaves': hp.quniform('num_leaves', 20, 150, 1),\n",
    "    'learning_rate': hp.loguniform('learning_rate', np.log(0.01), np.log(0.5)),\n",
    "    'subsample_for_bin': hp.quniform('subsample_for_bin', 20000, 300000, 20000),\n",
    "    'min_child_samples': hp.quniform('min_child_samples', 20, 500, 5),\n",
    "    'reg_alpha': hp.uniform('reg_alpha', 0.0, 1.0),\n",
    "    'reg_lambda': hp.uniform('reg_lambda', 0.0, 1.0),\n",
    "    'colsample_bytree': hp.uniform('colsample_by_tree', 0.6, 1.0),\n",
    "    'is_unbalance': hp.choice('is_unbalance', [True, False]),\n",
    "    'class_weight': hp.choice('class_weight', ['balanced', None]),#importantísimo\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4-Optimización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import tpe\n",
    "# Create the algorithm\n",
    "tpe_algorithm = tpe.suggest\n",
    "from hyperopt import fmin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import Trials\n",
    "\n",
    "# Record results\n",
    "trials = Trials()\n",
    "# Create a file and open a connection\n",
    "OUT_FILE = 'Datos/bayes_test.csv'\n",
    "of_connection = open(OUT_FILE, 'w')\n",
    "writer = csv.writer(of_connection)\n",
    "\n",
    "ITERATION = 0\n",
    "\n",
    "# Write column names\n",
    "headers = ['loss', 'hyperparameters', 'iteration', 'runtime', 'score']\n",
    "writer.writerow(headers)\n",
    "of_connection.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████| 10/10 [02:05<00:00, 14.87s/it, best loss: 0.037083527045228104]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'boosting_type': 0,\n",
       " 'class_weight': 0,\n",
       " 'colsample_by_tree': 0.9327992276257075,\n",
       " 'gdbt_subsample': 0.8372297281400392,\n",
       " 'is_unbalance': 1,\n",
       " 'learning_rate': 0.020972552144714853,\n",
       " 'min_child_samples': 110.0,\n",
       " 'num_leaves': 124.0,\n",
       " 'reg_alpha': 0.678907006302082,\n",
       " 'reg_lambda': 0.08624711694400033,\n",
       " 'subsample_for_bin': 220000.0}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Global variable\n",
    "global  ITERATION\n",
    "MAX_EVALS = 10\n",
    "N_FOLDS = 5\n",
    "ITERATION = 0\n",
    "\n",
    "# Run optimization\n",
    "best = fmin(fn = objective, space = space, algo = tpe.suggest, trials = trials,\n",
    "            max_evals = MAX_EVALS)\n",
    "\n",
    "best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.read_csv(OUT_FILE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Sort with best values on top\n",
    "results=results.sort_values('score', ascending = False).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"{'boosting_type': 'gbdt', 'class_weight': 'balanced', 'colsample_bytree': 0.9327992276257075, 'is_unbalance': False, 'learning_rate': 0.020972552144714853, 'min_child_samples': 110, 'num_leaves': 124, 'reg_alpha': 0.678907006302082, 'reg_lambda': 0.08624711694400033, 'subsample_for_bin': 220000, 'subsample': 0.8372297281400392, 'n_estimators': 99}\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.loc[0, 'hyperparameters']#el mejor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"{'boosting_type': 'gbdt', 'class_weight': 'balanced', 'colsample_bytree': 0.7900995784745264, 'is_unbalance': True, 'learning_rate': 0.0343034148498665, 'min_child_samples': 250, 'num_leaves': 91, 'reg_alpha': 0.2659708831339006, 'reg_lambda': 0.5710140558171175, 'subsample_for_bin': 160000, 'subsample': 0.9358923747737681, 'n_estimators': 62}\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.loc[1, 'hyperparameters']# el siguiente"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
